data_dir: /var/lib/vector
sources:
  gotrue_log:
    type: file
    include: 
      - /var/log/services/gotrue.log

  postgrest_log:
    type: file
    include: 
      - /var/log/services/postgrest.log

  pgbouncer_log:
    type: file
    include: 
      - /var/log/services/pgbouncer.log

  pitr_log:
    type: file
    include:
      - /var/log/wal-g/pitr.log
    read_from: end

  postgres_log:
    type: file
    include:
      - /var/log/postgresql/postgres*.csv
    read_from: end
    multiline:
      start_pattern: '^20[0-9][0-9]-[0-1][0-9]-[0-3][0-9] [0-2][0-9]:[0-5][0-9]:[0-5][0-9].[0-9]{3} UTC,"'
      mode: halt_before
      condition_pattern: '^20[0-9][0-9]-[0-1][0-9]-[0-3][0-9] [0-2][0-9]:[0-5][0-9]:[0-5][0-9].[0-9]{3} UTC,"'
      timeout_ms: 500

transforms:
  csv_parse:
    type: remap
    inputs:
      - postgres_log
    source: |-
      csv_data = parse_csv!(.message)
      .metadata.parsed.timestamp = csv_data[0]
      .metadata.parsed.user_name = csv_data[1]
      .metadata.parsed.database_name = csv_data[2]
      .metadata.parsed.process_id = to_int(csv_data[3]) ?? null
      .metadata.parsed.connection_from = csv_data[4]
      .metadata.parsed.session_id = csv_data[5]
      .metadata.parsed.session_line_num = to_int(csv_data[6]) ?? null
      .metadata.parsed.command_tag = csv_data[7]
      .metadata.parsed.session_start_time = csv_data[8]
      .metadata.parsed.virtual_transaction_id = csv_data[9]
      .metadata.parsed.transaction_id = to_int(csv_data[10]) ?? null
      .metadata.parsed.error_severity = csv_data[11]
      .metadata.parsed.sql_state_code = csv_data[12]
      .metadata.parsed.message = csv_data[13]
      .metadata.parsed.detail = csv_data[14]
      .metadata.parsed.hint = csv_data[15]
      .metadata.parsed.internal_query = csv_data[16]
      .metadata.parsed.internal_query_pos = to_int(csv_data[17]) ?? null
      .metadata.parsed.context = csv_data[18]
      .metadata.parsed.query = csv_data[19]
      .metadata.parsed.query_pos = to_int(csv_data[20]) ?? null
      .metadata.parsed.location = csv_data[21]
      .metadata.parsed.application_name = csv_data[22]
      .metadata.parsed.backend_type = csv_data[23]
      .metadata.parsed.leader_pid = to_int(csv_data[24]) ?? null
      .metadata.parsed.query_id = to_int(csv_data[25]) ?? null

      z_ts = replace!(.metadata.parsed.timestamp, " UTC", "Z")
      iso8601_ts = replace(z_ts, " ", "T")

      .timestamp = iso8601_ts

      # Sends original csv log line duplicating data. Used for QA.
      # .metadata.parsed_from = .message

      .message = del(.metadata.parsed.message)
      .metadata.host = del(.host)
      del(.file)
      del(.source_type)

  drop_metrics:
    type: filter
    inputs:
      - csv_parse
    condition: >
      .metadata.parsed.application_name != "postgres_exporter" && .metadata.parsed.application_name != "realtime_rls" && !contains!(.message, "disconnection: session time")

  add_project_ref:
    type: add_fields
    inputs:
      - drop_metrics
    fields:
      project: {{ .ProjectRef }}

  auth_failures:
    type: filter
    inputs:
      - postgres_log
    condition: >-
      contains!(.message, "password authentication failed for user")

  filter_pgbouncer_stats:
    type: filter
    inputs:
      - pgbouncer_log
    condition: >-
      !starts_with!(.message, "stats:") && !starts_with!(.message, "kernel file descriptor limit") && !contains!(.message, "FIXME")

  filter_postgrest_stats:
    type: filter
    inputs:
      - postgrest_log
    condition: >-
      !starts_with!(.message, "+") && !starts_with!(.message, "INFO:") && !contains!(.message, "Admin server listening")

  gotrue_to_object:
    inputs:
      - gotrue_log
    type: remap
    source: |2-
                .project = "{{ .ProjectRef }}"

                .parsed, err = parse_json(.message)
                if err == null {
                  .metadata = .parsed
                  .metadata.msg = .parsed.msg
                  .timestamp = del(.metadata.time)
                }
                del(.parsed)
                .metadata.host = del(.host)

                del(.source_type)
                del(.PRIORITY)
                del(.SYSLOG_FACILITY)
                del(.SYSLOG_IDENTIFIER)
                del(._BOOT_ID)
                del(._CAP_EFFECTIVE)
                del(._CMDLINE)
                del(._COMM)
                del(._EXE)
                del(._GID)
                del(._MACHINE_ID)
                del(._PID)
                del(._SELINUX_CONTEXT)
                del(._STREAM_ID)
                del(._SYSTEMD_CGROUP)
                del(._SYSTEMD_INVOCATION_ID)
                del(._SYSTEMD_SLICE)
                del(._SYSTEMD_UNIT)
                del(._TRANSPORT)
                del(._UID)
                del(.__MONOTONIC_TIMESTAMP)
                del(.__REALTIME_TIMESTAMP)

  postgrest_to_object:
    inputs:
      - filter_postgrest_stats
    type: remap
    source: |2-
                .project = "{{ .ProjectRef }}"

                # removes timestamp embedded in log since Vector already sends it
                .message = replace!(.message, r'^\d+/\w+/\d+:\d+:\d+:\d+\s\+\d+:\s', "")
                .metadata.host = del(.host)
                del(.source_type)
                del(.PRIORITY)
                del(.SYSLOG_FACILITY)
                del(.SYSLOG_IDENTIFIER)
                del(._BOOT_ID)
                del(._CAP_EFFECTIVE)
                del(._CMDLINE)
                del(._COMM)
                del(._EXE)
                del(._GID)
                del(._MACHINE_ID)
                del(._PID)
                del(._SELINUX_CONTEXT)
                del(._STREAM_ID)
                del(._SYSTEMD_CGROUP)
                del(._SYSTEMD_INVOCATION_ID)
                del(._SYSTEMD_SLICE)
                del(._SYSTEMD_UNIT)
                del(._TRANSPORT)
                del(._UID)
                del(.__MONOTONIC_TIMESTAMP)
                del(.__REALTIME_TIMESTAMP)

  pgbouncer_to_object:
    inputs:
      - filter_pgbouncer_stats
    type: remap
    source: |2-
                .project = "{{ .ProjectRef }}"
                .metadata.host = del(.host)
                del(.source_type)
                del(.PRIORITY)
                del(.SYSLOG_IDENTIFIER)
                del(._BOOT_ID)
                del(._CAP_EFFECTIVE)
                del(._CMDLINE)
                del(._COMM)
                del(._EXE)
                del(._GID)
                del(._MACHINE_ID)
                del(._PID)
                del(._SELINUX_CONTEXT)
                del(._SOURCE_REALTIME_TIMESTAMP)
                del(._SYSTEMD_CGROUP)
                del(._SYSTEMD_INVOCATION_ID)
                del(._SYSTEMD_SLICE)
                del(._SYSTEMD_UNIT)
                del(._TRANSPORT)
                del(._UID)
                del(.__MONOTONIC_TIMESTAMP)
                del(.__REALTIME_TIMESTAMP)

  pitr_to_object:
    inputs:
      - pitr_log
    type: remap
    source: |2-
                .project = "{{ .ProjectRef }}"

                .parsed, err = parse_key_value(.message)
                if err == null {
                  .metadata = .parsed
                  .metadata.host = del(.host)
                  .message = del(.metadata.msg)
                  .timestamp = del(.metadata.time)
                }

                del(.parsed)
                del(.source_type)
                del(.file)

  filter_pitr_error:
    inputs:
      - pitr_to_object
    type: filter
    condition: >
      .metadata.level != "info"

sinks:
  http_gotrue:
    type: "http"
    inputs:
      - gotrue_to_object
    encoding:
      codec: "json"
    method: "post"
    compression: none
    request:
      retry_max_duration_secs: 10
    uri: "https://{{ .LogflareHost }}/logs?api_key={{ .ApiKey }}&source={{ .GotrueSource }}"

  http_postgrest:
    type: http
    inputs:
      - postgrest_to_object
    encoding:
      codec: "json"
    method: "post"
    compression: none
    request:
      retry_max_duration_secs: 10
    uri: "https://{{ .LogflareHost }}/logs?api_key={{ .ApiKey }}&source={{ .PostgrestSource }}"

  http_pgbouncer:
    type: http
    inputs:
      - pgbouncer_to_object
    encoding:
      codec: json
    compression: none
    uri: "https://{{ .LogflareHost }}/logs?api_key={{ .ApiKey }}&source={{ .PgbouncerSource }}"

  http_pitr_error:
    type: http
    inputs:
      - filter_pitr_error
    encoding:
      codec: json
    compression: none
    uri: "https://{{ .LogflareHost }}/logs?api_key={{ .ApiKey }}&source={{ .PitrErrorsSource }}"

  http_postgres:
    type: http
    inputs:
      - add_project_ref
    encoding:
      codec: "json"
    method: "post"
    compression: none
    request:
      retry_max_duration_secs: 10
    uri: "https://{{ .LogflareHost }}/logs?api_key={{ .ApiKey }}&source={{ .DbSource }}"
    
  file_postgres:
    type: file
    inputs:
      - auth_failures
    encoding:
      codec: text
    path: >-
      /var/log/postgresql/auth-failures.csv
